{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "easiest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10Fsdv0ETPepOqo6ybXY5fah_dXUcijbj",
      "authorship_tag": "ABX9TyNyFMKfpCb0VnjUm1k6IWeg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitkumar9989/competition_main/blob/main/Helping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqrOHust_7Oq"
      },
      "source": [
        "#1st cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1j1JlYYYidU"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvJD9GDb99Qz"
      },
      "source": [
        "##The main class for the model making, Mianly two types\n",
        "###Convolutional layer\n",
        "##Api function\n",
        "\n",
        "This is a class which helps in making the model so nothing much up over here.... So as you can see in third cell of this notebook i have called the model... As the `your_model` function return's the pretrained model.. Hence we can save the model out of the function\n",
        "\n",
        "Arguments for the function\n",
        "\n",
        ">`filename`: (mandatory), pass the filename wherever is your images, those are the cracked images, the particular folder\n",
        "\n",
        ">`save_checkpoints`: (optional) (bool), this argument is optional\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2xunCfK_4Rv"
      },
      "source": [
        "#2nd cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyesK_6q6kcF"
      },
      "source": [
        "class your_model ():\n",
        "  def __init__ (self, filename, save_checkpoints=True, checkpoints_already_saved=False):\n",
        "    self.filename=filename #Your filename whaere you images are present\n",
        "    self.save_checkpoints=save_checkpoints\n",
        "  def models_api (self):\n",
        "    data_api=tf.keras.preprocessing.image_dataset_from_directory(directory=self.filename,\n",
        "                                                             label_mode='binary',\n",
        "                                                             batch_size=32,\n",
        "                                                             image_size=(224, 224),\n",
        "                                                             shuffle=False,\n",
        "                                                             interpolation='bilinear',\n",
        "                                                             smart_resize=True)\n",
        "\n",
        "    data_augmented=tf.keras.Sequential([\n",
        "                                        tf.keras.layers.experimental.preprocessing.RandomHeight(factor=0.2),\n",
        "                                        tf.keras.layers.experimental.preprocessing.RandomWidth(0.2),\n",
        "                                        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "    ])\n",
        "    model_base=tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "    inputs=tf.keras.layers.Input(shape=(224, 224, 3), name='first_layer')\n",
        "    augs=data_augmented(inputs)\n",
        "    model=model_base(augs, training=False)\n",
        "\n",
        "    layer_1=tf.keras.layers.GlobalMaxPool2D()(model)\n",
        "\n",
        "    outputs=tf.keras.layers.Dense(128, activation='relu')(layer_1)\n",
        "    outputs=tf.keras.layers.Dense(16, activation='relu')(outputs)\n",
        "    outputs=tf.keras.layers.Dense(16, activation='relu')(outputs)\n",
        "\n",
        "    output_real=tf.keras.layers.Dense(1, activation='sigmoid')(outputs)\n",
        "    model=tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics='accuracy')\n",
        "    if self.save_checkpoints==True:\n",
        "      model.fit(data_api, epochs=100, callbacks=[tf.keras.callbacks.LearningRateScheduler(lambda epochs: 1e-4*10**(epochs/200)),\n",
        "                                                 tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints.ckpt',\n",
        "                                                                                    save_weights_onlt=True,\n",
        "                                                                                    monitor='accuracy'),\n",
        "                                                 tf.keras.callbacks.EarlyStopping(patience=10, verbose=1,\n",
        "                                                                                  restore_best_weights=True,\n",
        "                                                                                  monitor='accuracy')])\n",
        "    else:\n",
        "      model.fit(data_api, epochs=1)\n",
        "      model.load_weights('checkpoints.ckpt')\n",
        "\n",
        "    return model\n",
        "  def model_cnn (self):\n",
        "    data=tf.keras.preprocessing.image.ImageDataGenerator(samplewise_center=True,\n",
        "                                                          featurewise_std_normalization=True,\n",
        "                                                          zca_epsilon=1e-4,\n",
        "                                                          shear_range=0.2,\n",
        "                                                          height_shift_range=0.2,\n",
        "                                                          width_shift_range=0.2,\n",
        "                                                          fill_mode='nearest',\n",
        "                                                          horizontal_flip=True)\n",
        "    data=data.flow_from_directory(directory='/content/drive/MyDrive/Face_data',\n",
        "                              target_size=(224, 224), \n",
        "                              class_mode='binary',\n",
        "                              shuffle=False,\n",
        "                              batch_size=32,\n",
        "                              interpolation='bilinear'\n",
        "                              )\n",
        "    \n",
        "    model_base=tf.keras.Sequential([\n",
        "                         tf.keras.layers.Conv2D(filters=128,\n",
        "                                                kernel_size=2,\n",
        "                                                activation='relu',\n",
        "                                                input_shape=(224, 224, 3)),\n",
        "                         tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "                         tf.keras.layers.Conv2D(128, 2, activation='relu'), \n",
        "\n",
        "                         tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "                         tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "                         tf.keras.layers.Conv2D(64, 3, activation='relu'),  \n",
        "\n",
        "                         tf.keras.layers.Conv2D(32, 2, activation='relu'),\n",
        "                         tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                                                   padding='same',\n",
        "                                                   data_format=None),\n",
        "                         tf.keras.layers.Conv2D(32, 2, activation='relu'),\n",
        "\n",
        "                         tf.keras.layers.Flatten(), \n",
        "\n",
        "                         tf.keras.layers.Dense(128, activation='relu'),\n",
        "                         tf.keras.layers.Dense(128, activation='relu'),\n",
        "                         tf.keras.layers.Dense(128, activation='relu'), \n",
        "\n",
        "                         tf.keras.layers.Dense(64, activation='relu'),\n",
        "                         tf.keras.layers.Dense(64, activation='relu'),\n",
        "                         tf.keras.layers.Dense(64, activation='relu'), \n",
        "\n",
        "                         tf.keras.layers.Dense(32, activation='relu'),\n",
        "                         tf.keras.layers.Dense(32, activation='relu'),\n",
        "                         tf.keras.layers.Dense(32, activation='relu'),  \n",
        "\n",
        "                         tf.keras.layers.Dense(16, activation='relu'),\n",
        "                         tf.keras.layers.Dense(16, activation='relu'),\n",
        "                         tf.keras.layers.Dense(16, activation='relu'), \n",
        "\n",
        "                         tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model_base.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00012),\n",
        "                    metrics='accuracy')\n",
        "    \n",
        "    model_base.fit(data, \n",
        "                   epochs=100, \n",
        "                   steps_per_epoch=len(data),\n",
        "                   callbacks=tf.keras.callbacks.EarlyStopping(monitor='accuracy',\n",
        "                                                              patience=10,\n",
        "                                                              verbose=1))\n",
        "\n",
        "    return model_base\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5duMmxI_znS"
      },
      "source": [
        "#3rd cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqnsH33bHzu8"
      },
      "source": [
        "#This is for the cnn model\n",
        "a=your_model(filename='/content/drive/MyDrive/Face_data')\n",
        "model=a.model_cnn()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Z-0g6JBhQV"
      },
      "source": [
        "model.save('Mymodel', save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}